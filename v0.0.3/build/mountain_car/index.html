<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Mountain Car · DecisionMakingProblems.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">DecisionMakingProblems.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../">DecisionMakingProblems.jl</a></li><li><a class="tocitem" href="../mdp/">MDP Usage</a></li></ul></li><li><span class="tocitem">MDP Models</span><ul><li><a class="tocitem" href="../hexworld/">Hex World</a></li><li><a class="tocitem" href="../2048/">2048</a></li><li><a class="tocitem" href="../cart_pole/">Cart-Pole</a></li><li class="is-active"><a class="tocitem" href>Mountain Car</a><ul class="internal"><li><a class="tocitem" href="#Problem"><span>Problem</span></a></li><li><a class="tocitem" href="#State-and-Action-Space"><span>State and Action Space</span></a></li><li><a class="tocitem" href="#Transitions"><span>Transitions</span></a></li><li><a class="tocitem" href="#Reward-Function-and-Termination-Condition"><span>Reward Function and Termination Condition</span></a></li></ul></li><li><a class="tocitem" href="../simple_lqr/">Simple Regulator</a></li><li><a class="tocitem" href="../collision_avoidance/">Aircraft Collision Avoidance</a></li></ul></li><li><span class="tocitem">POMDP Models</span><ul><li><a class="tocitem" href="../pomdp/">POMDP Usage</a></li><li><a class="tocitem" href="../crying_baby/">Crying Baby</a></li><li><a class="tocitem" href="../machine_replacement/">Machine Replacement</a></li><li><a class="tocitem" href="../catch/">Catch</a></li></ul></li><li><span class="tocitem">Simple Games</span><ul><li><a class="tocitem" href="../simplegame/">SimpleGame Usage</a></li><li><a class="tocitem" href="../prisoners_dilemma/">Prisoner&#39;s Dilemma</a></li><li><a class="tocitem" href="../rock_paper_scissors/">Rock-Paper-Scissors</a></li><li><a class="tocitem" href="../travelers/">Traveler&#39;s Problem</a></li></ul></li><li><span class="tocitem">POMG Models</span><ul><li><a class="tocitem" href="../pomg/">POMG Usage</a></li><li><a class="tocitem" href="../multicaregiver/">Multi-Caregiver Crying Baby</a></li></ul></li><li><span class="tocitem">Markov Game</span><ul><li><a class="tocitem" href="../mg/">MG Usage</a></li><li><a class="tocitem" href="../predator_prey/">Predatory-Prey Hex World</a></li></ul></li><li><span class="tocitem">Dec-POMDP</span><ul><li><a class="tocitem" href="../decpomdp/">DecPOMDP Usage</a></li><li><a class="tocitem" href="../collab_predator_prey/">Collaborative Predatory-Prey Hex World</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">MDP Models</a></li><li class="is-active"><a href>Mountain Car</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Mountain Car</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/algorithmsbooks/DecisionMakingProblems.jl/blob/master/docs/src/mountain_car.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Mountain-Car"><a class="docs-heading-anchor" href="#Mountain-Car">Mountain Car</a><a id="Mountain-Car-1"></a><a class="docs-heading-anchor-permalink" href="#Mountain-Car" title="Permalink"></a></h1><h2 id="Problem"><a class="docs-heading-anchor" href="#Problem">Problem</a><a id="Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Problem" title="Permalink"></a></h2><p>In the mountain car problem, a vehicle must drive to the right, out of a valley. The valley walls are steep enough that blindly accelerating toward the goal with insufficient speed causes the vehicle to come to a halt and slide back down. The agent must learn to accelerate left first, in order to gain enough momentum on the return to make it up the hill.</p><p>The mountain car problem is a good example of a problem with delayed return. Many actions are required to get to the goal state, making it difficult for an untrained agent to receive anything other than consistent unit penalties. The best learning algorithms are able to efficiently propagate knowledge from trajectories that reach the goal back to the rest of the state space.</p><p><img src="../figures/img11.svg" alt="Visualization of Mountain Car"/></p><h2 id="State-and-Action-Space"><a class="docs-heading-anchor" href="#State-and-Action-Space">State and Action Space</a><a id="State-and-Action-Space-1"></a><a class="docs-heading-anchor-permalink" href="#State-and-Action-Space" title="Permalink"></a></h2><p>The state space, action space and observation space are</p><p class="math-container">\[\begin{aligned}
\mathcal{S} &amp;= [-1.2, 0.6] \times [-0.07, 0.07] \\
\mathcal{A} &amp;= \{-1, 0, 1\} \\
\end{aligned}\]</p><p>The state is the vehicle’s horizontal position <span>$x \in [−1.2, 0.6]$</span> and speed <span>$v \in [−0.07, 0.07].$</span> At any given time step, the vehicle can accelerate left <span>$(a = −1)$</span>, accelerate right <span>$(a = 1)$</span>, or coast <span>$(a = 0)$</span>.</p><h2 id="Transitions"><a class="docs-heading-anchor" href="#Transitions">Transitions</a><a id="Transitions-1"></a><a class="docs-heading-anchor-permalink" href="#Transitions" title="Permalink"></a></h2><p>Transitions in the mountain car problem are deterministic:</p><p class="math-container">\[\begin{aligned}
v&#39; &amp;\rightarrow v + 0.001a - 0.0025 \cos(3x) \\
x&#39; &amp;\rightarrow x + v&#39;
\end{aligned}\]</p><p>The gravitational term in the speed update is what drives the under-powered vehicle back toward the valley floor. Transitions are clamped to the bounds of the state-space.</p><p>A visualization of the problem is shown below:</p><h2 id="Reward-Function-and-Termination-Condition"><a class="docs-heading-anchor" href="#Reward-Function-and-Termination-Condition">Reward Function and Termination Condition</a><a id="Reward-Function-and-Termination-Condition-1"></a><a class="docs-heading-anchor-permalink" href="#Reward-Function-and-Termination-Condition" title="Permalink"></a></h2><p>We receive <span>$−1$</span> reward every turn, and terminate when the vehicle makes it up the right side of the valley past <span>$x = 0.6$</span>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../cart_pole/">« Cart-Pole</a><a class="docs-footer-nextpage" href="../simple_lqr/">Simple Regulator »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 1 May 2021 17:27">Saturday 1 May 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
